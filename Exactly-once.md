### Exactly-Once
만약 데이터를 읽고 작업하여 저장하는 과정에서 장애가 발생하여 중복된 데이터가 저장되거나 누락되는 경우가 있으면 원치 않은 결과를 얻을 수 있습니다.  
따라서 데이터는 정확히 1번만 처리 되어야 합니다.  
이 때 모든 데이터가 1번만 처리 되는 것을 Exactly-once라고 합니다.  
  
우선 데이터 처리는 완결성 측면에서 처리 시간 동안 나타난 모든 데이터는 정확히 1번 처리되고 늦은 데이터는 명목적으로 무시해야 됩니다.  
Flink는 분산된 데이터를 읽고 처리하여 저장할 때 어떻게 1번만 처리되도록 구현했을까요?  
  
플링크 스트리밍은 주기적으로 스냅샷을 생성합니다. 스냅샷은 비동기 방식으로 저장되기 때문에 스냅샷을 생성할 동안 실행중인 연산 작업이 중지될 필요가 없습니다. 이러한 방식을 통해 지연 시간을 낮출 수 있습니다.  
그리고 데이터 스트림에 마커(베리어)를 삽입하여 스냅샷을 구현합니다. 만약 워커에 오류가 발생하는 경우 마지막 스냅샷(checkpoint)으로 상태를 롤백합니다.  

### End-to-End Exactly-Once
주로 Flink를 사용할 때 외부 시스템에서 데이터를 읽고 저장하여 사용합니다.  
예를 들어 Kafka에서 이벤트를 읽고 DB에 처리 결과를 저장한다고 생각해봅시다. 이 때 정확히 1번 처리를 어떻게 구현되는지 알아봅시다.  
크게 작업은 3가지로 분리될 것 입니다.  
- Source(읽기)
- Window(작업)
- Sink(저장)

1. Source(읽기)
만약 Kafka 토픽에서 이벤트를 읽는 경우 오프셋을 체크포인트에 저장하여 Window(작업)을 합니다.  
따라서 장애가 발생 시 마지막 체크포인트로 복구가 되기 때문에 오프셋 정보를 가져와서 다시 재작업을 할 수 있습니다.  
  
2. Window(작업)
Flink는 장애가 발생 시 마지막 체크포인트 시점으로 돌아가서 모든 작업을 재수행합니다.  
  
3. Sink(저장)
장애가 발생 시 가장 최근의 체크포인트로 롤백되지만, 데이터가 중복 저장되지 않을까라는 생각이 들 수 있습니다.  
Flink에서는 Two-phase commit(2pc)을 통해 해당 문제를 해결합니다.  
  
Two-phase commitdms 4단계로 이뤄집니다.  
- beginTransaction : 새로운 체크포인트가 시작될 때 모든 데이터는 임시 저장소에 기록합니다.  
- preCommit : 체크포인트가 도착하면 file을 flush, close하고 write하지는 않습니다. JobManager는 모든 sink 연산자들이 preCommit단계를 통과해야 체크포인트를 커밋할 수 있습니다.
- commit : preCommit이 완료된 경우 temp dir에서 actual dir로 이동시킵니다.  
- abort : 체크포인트가 실패하거나 장애가 발생하는 경우 temp dir을 삭제하거나 DB 트랜잭션을 중단합니다.
  
작업 단계를 요약해보면 바로 외부에 저장하는 것이 아닌 임시 저장소에 저장 후 이상이 없는 경우 DB에 테이블을 저장합니다.  
  
### 정리
- Flink는 Exactly-once(정확히 1번 처리)를 지원한다
- Exactly-once를 보장하기 위해서는 Checkpoint가 중요하다.
- 에러가 발생하는 경우 성공한 마지막 Checkpoint(스냅샷)으로 이동하여 복구한다.
- 소스에서 이벤트를 받을 때 오프셋 같은 Unique ID를 통해

### Ref:
- https://medium.com/codex/how-we-almost-achieve-end-to-end-exactly-once-processing-with-flink-28d2c013b5c1
- 